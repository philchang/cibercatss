{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ce1688f",
   "metadata": {},
   "source": [
    "# ODE Integration\n",
    "$\\newcommand{\\vec}[1]{{\\bf #1}}$\n",
    "$\\newcommand{\\ee}{\\end{eqnarray}}$\n",
    "\n",
    "\n",
    "## Euler's Method\n",
    "\n",
    "Consider the following first order ordinary differential equation.\n",
    "$$\n",
    "\\frac {d\\vec{y}}{dt} = \\vec{f}(\\vec{y}, t),\n",
    "$$\n",
    "where $\\vec{y}$ is a vector of variables, $t$ is the independent variable, and $\\vec{f}$ is some arbitrary vector function of $\\vec{y}$ and $t$.  We can use our definition of derivative to write: \n",
    "$$\n",
    "\\frac {d\\vec{y}}{dt} \\approx \\frac {\\vec{y}_{i+1} - \\vec{y}_i}{\\Delta t} = \\vec{f}(\\vec{y}_i, t_i),\\label{eq:explicit}\n",
    "$$\n",
    "where $\\Delta t = t_{i+1} - t_i$.  This is not the only choice that could have been made, it is also possible to write it as \n",
    "$$\n",
    "\\frac {\\vec{y}_{i+1} - \\vec{y}_i}{\\Delta t} = \\vec{f}(\\vec{y}_{i+1}, t_{i+1}). \\label{eq:implicit}\n",
    "$$\n",
    "The difference between these two is the choice of either $t_{i}$ or $t_{i+1}$ on the right hand side.  Equation (\\ref{eq:implicit}) gives rise to implicit methods which are harder to code up, but offers potentially greater stability and speed.  Instead, we will focus on equation (\\ref{eq:explicit}).  \n",
    "\n",
    "If we know the value at $\\vec{y}(t_i)$, we can solve for $\\vec{y}(t_{i+1})$ to be\n",
    "$$\n",
    "\\vec{y}_{i+1} = \\vec{y}_i + \\vec{f}(\\vec{y}_i, t_i)\\Delta t.\\label{eq:euler method}\n",
    "$$\n",
    "This method is known as Euler's method.  As an aside, it we take $\\vec{f}$ to be a scalar function of just $t$, then it just becomes an ordinary integral.  Hence, the methodology we describe here is directly relevant for numerical integration so we don't need a separate discussion for it.\n",
    "\n",
    "Equation (\\ref{eq:euler method}) gives the correct answer for $\\Delta t \\rightarrow 0$, but it should never be used solving any equations you code up on a computer as superior methods abound\\footnote{Of course in the movie Hidden Figures, the lead protagonist uses Euler's method to ensure that John Glenn lands safely. Then again the computer was a human being.}.  To see why Euler's method is not recommended, let consider the error that this algorithm introduces for finite $\\Delta t$.  We do a Taylor expansion of the true solution, $\\vec{y}(t)$:\n",
    "$$\n",
    "\\vec{y}_{i+1} \\approx \\vec{y}_i + \\frac{d\\vec{y}}{d t}(t_i)\\Delta t + \\frac 1 2 \\frac{d^2\\vec{y}}{d t^2}(t_i)\\Delta t^2 + \\mathcal{O}(\\Delta t^3)\n",
    "$$\n",
    "The first two terms constitute Euler's method, so for each time step, we will accumulate an error that is proportional to $\\Delta t^2$.  Since the number of steps over an interval $T$ goes like $T/\\Delta t$, then the total error scales like $1/\\Delta t$.  So for sufficiently small $\\Delta t$, then the error is reduced, but it comes at the cost of lots of steps.  Because of the scaling with error, Euler's method is known as a first-order method.  To get better results we want scaling that reduces the error as much as possible. \n",
    "\n",
    "As an example, lets consider the equation \n",
    "$$\n",
    "\\frac {dy}{dt} = \\cos(t).\n",
    "$$\n",
    "We can see that we can solve this analytically by noting\n",
    "$$\n",
    "y(t) = \\int\\cos(t) dt = \\sin(t) + C,\n",
    "$$\n",
    "where $C$ is a constant.  Let see how we can do this numerically. First we define a function for the derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d90923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# implement the integrand above.\\\n",
    "def derivatives( t, y) : \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5c1625",
   "metadata": {},
   "source": [
    "Now you might wonder about the second variable in the derivatives function. We shall return to this shortly. Now let us define the Euler method.  \n",
    "$$\n",
    "y(t+\\Delta t) = y(t) + \\frac{dy}{dy}\\Delta t\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12cb310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement the euler's method as using dy/dt as defined by derivatives above\n",
    "\n",
    "def euler(t, delta_t, y) : \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea48fcaa",
   "metadata": {},
   "source": [
    "Note that the euler function above follows the exact definition of euler's method as defined above.  Now lets drive this between $t=0$ and $t=100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_euler(N=1000, t0=0, t1=100) :\n",
    "    delta_t = (t1-t0)/N\n",
    "    y = 0\n",
    "\n",
    "    t_array = np.arange(t0,t1,delta_t)\n",
    "    y_array = np.zeros(t_array.size+1)\n",
    "\n",
    "    y_array[0] = y\n",
    "    for i in range(t_array.size):\n",
    "        y_array[i+1] = euler(t_array[i], delta_t, y_array[i])\n",
    "    return t_array, y_array"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c91600ef",
   "metadata": {},
   "source": [
    "Great.  Now lets plot this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t_array, y_array = run_euler()\n",
    "plt.plot(t_array, y_array[:-1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8b8d9d",
   "metadata": {},
   "source": [
    "## Runge-Kutta 2 step (RK2)\n",
    "\n",
    "Euler's method is beautifully simple, elegant, and not that accurate.  There are much better methods abound, mainly ones that are much more accurate.  There is a slightly more complicated method that can give much better answers.\n",
    "\n",
    "Runge-Kutta methods are an example of predictor-corrector methods.  That is, it ``predicts'' the value at $\\vec{y}_{i+1}$ from the current solution at $\\vec{y}_i$.  Using this predicted value, it performs a ``corrector'' step to increase the accuracy of the solution.  The generic two-step Runge-Kutta method is as follows:\n",
    "$$\n",
    "\\vec{k}_1 = \\Delta t \\vec{f}(\\vec{y}_i, t_i) \n",
    "$$\n",
    "$$\n",
    "\\vec{k}_2 = \\Delta t \\vec{f}(\\vec{y}_i + \\beta \\vec{k}_1, t_i + \\alpha \\Delta t) \n",
    "$$\n",
    "$$\n",
    "\\vec{y}_{i+1} = \\vec{y}_i + a \\vec{k}_1 + b \\vec{k}_2\n",
    "$$\n",
    "where $\\vec{k}_1$ is the ``predictor'' and is the same as an Euler step, $\\vec{k}_2$ is the ``corrector'', and the $i+1$ step is some linear combination of the two.  The constants, $\\alpha$, $\\beta$, $a$, and $b$ are chosen to make the entire algoritm accurate to $\\mathcal{O}(\\Delta t^3)$.  To determine these unknown constants, let perform a Taylor expansion of $\\vec{y}_{i+1}$\n",
    "$$\n",
    "\\vec{y}_{i+1} = \\vec{y}_i + \\frac{d\\vec{y}}{d t}(t_i)\\Delta t + \\frac 1 2 \\frac{d^2\\vec{y}}{dt^2}(t_i)\\Delta t^2\n",
    "$$\n",
    "Now \n",
    "$$\n",
    "\\frac{d^2\\vec{y}}{dt^2}(t_i) = \\frac {d\\vec{f}(\\vec{y},t)}{dt} = \\frac {\\partial \\vec{f}(\\vec{y},t)}{\\partial t} + \\frac{d\\vec{y}}{dt}\\cdot\\vec{\\nabla}_{\\vec{y}}\\vec{f} \n",
    "$$\n",
    "$$\n",
    "= \\frac {\\partial \\vec{f}(\\vec{y},t)}{\\partial t} + \\vec{f}\\cdot\\vec{\\nabla}_{\\vec{y}}\\vec{f}\n",
    "$$  \n",
    "Thus we have \n",
    "\\be\n",
    "\\vec{y}_{i+1} = \\vec{y}_i + \\vec{f}(\\vec{y}_i, t_i)\\Delta t + \\frac 1 2 \\left(\\frac {\\partial \\vec{f}(\\vec{y}_i,t_i)}{\\partial t} + \\vec{f}(\\vec{y}_i,t_i)\\cdot\\vec{\\nabla}_{\\vec{y}}\\vec{f}(\\vec{y}_i,t_i)\\right)\\Delta t^2 +\\mathcal{O}(\\Delta t^3)\\label{eq:2nd order}\n",
    "\\ee\n",
    "Now we Taylor expand out $\\vec{k}_2$ to find\n",
    "\\be\n",
    "\\vec{k}_2 &=& \\Delta t \\vec{f}(\\vec{y}_i + \\beta \\vec{k}_1, t_i + \\alpha \\Delta t) \\\\\n",
    "&=& \\Delta t\\left( \\vec{f}(\\vec{y}_i, t_i) + \\alpha\\Delta t\\frac {\\partial \\vec{f}(\\vec{y}_i,t_i)}{\\partial t} + \\beta\\Delta t \\vec{f}\\cdot\\vec{\\nabla}_{\\vec{y}}\\vec{f}(\\vec{y}_i,t_i)\\right)\n",
    "\\ee\n",
    "Putting this all together, we have \n",
    "\\be\n",
    "\\vec{y}_{i+1} &=& \\vec{y}_i + (a+b)\\Delta t \\vec{f}(\\vec{y}_i, t_i) + b\\Delta t^2\\left(\\alpha\\frac {\\partial \\vec{f}(\\vec{y}_i,t_i)}{\\partial t} + \\beta\\vec{f}\\cdot\\vec{\\nabla}_{\\vec{y}}\\vec{f}(\\vec{y}_i,t_i) \\right)+\\mathcal{O}(\\Delta t^3)\\label{eq:rk2 expansion}\n",
    "\\ee\n",
    "Comparing Equations (\\ref{eq:2nd order}) and (\\ref{eq:rk2 expansion}), we get the following conditions:\n",
    "\\be\n",
    "a+b = 1 \\qquad b\\alpha = \\frac 1 2 \\qquad b\\beta = \\frac 1 2,\n",
    "\\ee\n",
    "or 3 equation for 4 unknowns.  So that mean there exist a infinite number of second order schemes that are possible, e.g., error per step that goes likes $\\Delta t^3$, so the total error over an interval goes like $\\Delta t^2$.  So using $\\alpha$ as a parameter, we have \n",
    "\\be\n",
    "\\beta = \\alpha \\qquad b = \\frac 1 {2\\alpha} \\qquad a = 1 - \\frac 1 {2\\alpha}\n",
    "\\ee\n",
    "So a generic second order Runge-Kutta scheme is then\n",
    "\\be\n",
    "\\vec{k}_1 &=& \\Delta t \\vec{f}(\\vec{y}_i, t_i) \\\\\n",
    "\\vec{k}_2 &=& \\Delta t \\vec{f}(\\vec{y}_i + \\alpha \\vec{k}_1, t_i + \\alpha \\Delta t) \\\\\n",
    "\\vec{y}_{i+1} &=& \\vec{y}_i + \\left(1 - \\frac 1 {2\\alpha}\\right) \\vec{k}_1 + \\frac {\\vec{k}_2} {2\\alpha} \n",
    "\\ee\n",
    "\n",
    "A few famous examples are \n",
    "\\begin{itemize}\n",
    "    \\item Midpoint method: $\\alpha = 1/2$ Estimate the values of y at the midpoint and solve for the derivative at the midpoint.  Use this midpoint derivative to complete the integration.  Note that prefactor in front of $\\vec{k}_1$ in this case is zero.\n",
    "    \\item Heun's Method: $\\alpha = 1$ Estimate the values of y at the endpoint and give equal weight to both starting and endpoints to compute the derivative.\n",
    "\\end{itemize}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef40e7d",
   "metadata": {},
   "source": [
    "SEIR Model Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b3889a",
   "metadata": {},
   "source": [
    "## Higher Order ODEs\n",
    "\n",
    "Thus far we have discussed the case of first order odes.  What about higher order ODEs.  It turns out that there is a very simple extension to arbitrary high order ODEs.  The trick is it identify higher order derivatives as variables in themselves.  Consider the ODE\n",
    "$$\n",
    "\\sum_n^N\\frac{d^n f}{dx^n} = 0\n",
    "$$\n",
    "We can write this as a sum first order ODEs by the identification of \n",
    "$$\n",
    "f_i = \\frac{df_{i-1}}{dx} \\qquad\\textrm{and}\\qquad f_0 = f\n",
    "$$\n",
    "Thus we have \n",
    "$$\n",
    "\\frac{df_{N-1}}{dx} + \\sum_i^{N-1} f_i = 0,\n",
    "$$\n",
    "$$\n",
    "\\frac{df}{dx} = f_1\n",
    "$$\n",
    "$$\n",
    "\\frac{df_1}{dx} = f_2\n",
    "$$\n",
    "$$\n",
    " . . . .\n",
    "$$\n",
    "$$\n",
    "\\frac{df_{N-2}}{dx} = f_{N-1}.\n",
    "$$\n",
    "So this converts a Nth order ODE to N first order ODEs, which we can solve.\n",
    "\n",
    "As an example lets try a simple harmonic oscillator \n",
    "$$\n",
    "\\frac{d^2 x}{dt^2} = -x\n",
    "$$\n",
    "We of course know that the solution is \n",
    "$$\n",
    "x(t) = A\\cos(t+\\phi)\n",
    "$$\n",
    "\n",
    "This is second order so we break this up into 2 first order equations\n",
    "$$\n",
    "\\frac{dx}{dt} = v\n",
    "\\frac{dv}{dt} = -x\n",
    "$$\n",
    "Now lets implement this numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement the SHO derivative as 2 first order equations\n",
    "def SHO_derivatives(t,y) :\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da2f27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_SHO_rk2(t,delta_t) :\n",
    "    y = np.zeros(2)\n",
    "    y[0] = 1 # set initial condition\n",
    "    t1 = 0\n",
    "    while t1 < t : \n",
    "        delta_t = min(t-t1,delta_t)\n",
    "        # implement the rk2 step function\n",
    "        pass\n",
    "    return y\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython import display \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    # Get the point from the points list at index i\n",
    "    delta_t = 0.05\n",
    "    y = run_SHO_rk2(i*delta_t, delta_t)\n",
    "    ax.plot(y[0], 0., color='green', marker='o')\n",
    "    # Set the x and y axis to display a fixed range\n",
    "    ax.set_xlim([-1.2, 1.2])\n",
    "    ax.set_ylim([-1,1])\n",
    "ani = FuncAnimation(fig, animate, frames=250, interval=20, repeat=False)\n",
    "video = ani.to_html5_video()\n",
    "html = display.HTML(video)\n",
    "display.display(html)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f862bb",
   "metadata": {},
   "source": [
    "Now challenge problem.  Let's consider a very classic problem from astronomy.  Two massive bodies interacting gravitationally.  The force is a 3-d force which is defined by\n",
    "$$\n",
    "F = -\\frac{M_1 M_2}{r^2}\n",
    "$$\n",
    "we will scale out newton's constant, $G$, here. Suppose you have two bodies.  Go ahead and implement the derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265adc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_massive = 2\n",
    "N_bodies = N_massive\n",
    "M = np.array([1.0, 0.25])\n",
    "\n",
    "# given N bodies, implement the force equations as stated above.\n",
    "def Nbody_derivatives(t,y) :\n",
    "    pass\n",
    "    \n",
    "# some simple initial conditions\n",
    "def initial_conditions() : \n",
    "    pos_and_vel = np.zeros([N_bodies,6])\n",
    "\n",
    "    pos_and_vel[0,0] = -1\n",
    "    pos_and_vel[0,4] = -0.25\n",
    "    pos_and_vel[1,0] = 1\n",
    "    pos_and_vel[1,4] = 0.25\n",
    "    return pos_and_vel\n",
    "\n",
    "def run_Nbody_rk2(tend,tframe,dt) :\n",
    "    pos_and_vel = initial_conditions()\n",
    "    y = pos_and_vel\n",
    "    t = 0\n",
    "    tnext = tframe\n",
    "    positions = []\n",
    "    while t<tend :\n",
    "        while t < tnext :\n",
    "            delta_t = min(tnext-t,dt)\n",
    "            # compute using rk2\n",
    "        positions.append(pos_and_vel[:,0:3].copy())\n",
    "        tnext += tframe\n",
    "    return positions\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "frames =100\n",
    "tframe = 0.25\n",
    "dt = 0.025\n",
    "\n",
    "positions = run_Nbody_rk2(frames*tframe, tframe, dt)\n",
    "\n",
    "def animate(i, positions):\n",
    "    ax.clear()\n",
    "    # Get the point from the points list at index i\n",
    "    pos = positions[i]\n",
    "    ax.scatter(pos[:,0], pos[:,1], color='green', marker='o')\n",
    "    # Set the x and y axis to display a fixed range\n",
    "    ax.set_xlim([-5, 5])\n",
    "    ax.set_ylim([-5,5])\n",
    "ani = FuncAnimation(fig, lambda i : animate(i, positions), frames=len(positions), interval=50, repeat=False)\n",
    "video = ani.to_html5_video()\n",
    "html = display.HTML(video)\n",
    "display.display(html)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d851d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
