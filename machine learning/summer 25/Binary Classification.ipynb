{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3baf5dbd-7118-41b4-b5d4-8f51d616a44d",
   "metadata": {},
   "source": [
    "# Binary Classification on Breast Cancer Dataset\n",
    "\n",
    "In this notebook, we will practice binary classification on the Breast Cancer dataset, which is widely used for testing classification algorithms. Our goal is to predict whether a tumor is malignant or benign based on various features.\n",
    "\n",
    "### Dataset\n",
    "The Breast Cancer dataset is available through `sklearn.datasets`. Each data point represents a tumor, with features such as radius, texture, smoothness, and other measurements. The target variable indicates whether the tumor is malignant (1) or benign (0).\n",
    "\n",
    "Let's start by loading the dataset and exploring it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99620052-7044-4eaa-82bf-f4251d2f3878",
   "metadata": {},
   "source": [
    "## Loading and Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17c1e9-9f95-4c7c-a245-9a8c5839d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Convert to DataFrame for easier exploration\n",
    "df = pd.DataFrame(X, columns=data.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "# TODO: Display the first few rows of the DataFrame\n",
    "# Hint: Use the .head() method\n",
    "\n",
    "\n",
    "# TODO: Check for missing values and data types\n",
    "# Hint: Use .info() on the DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3a6179-bd02-4e45-8c04-63e8f6fcb0db",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2758845-3dcc-47fd-80b0-d54cd3a5b426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Check for missing values\n",
    "# Hint: Use .isnull().sum() to verify if there are any missing values\n",
    "\n",
    "\n",
    "# Since there are no missing values, we can proceed to feature scaling.\n",
    "\n",
    "# Standardize the feature values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# TODO: Initialize the scaler and transform features\n",
    "\n",
    "\n",
    "# TODO: Fit and transform features\n",
    "\n",
    "\n",
    "# TODO: Split the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae9b3a2-156c-4f08-a2a4-8f456a80857a",
   "metadata": {},
   "source": [
    "## Implementing Classification Algorithms\n",
    "\n",
    "We'll use cross-validation to evaluate each model. For cross-validation, we will use the cross_val_score function with 5 folds.\n",
    "\n",
    "Using cross-validation will give us more insight into the stability and robustness of each model by evaluating them on multiple subsets of the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbab4c49-5153-4f0a-aeb9-b48ba2338fd6",
   "metadata": {},
   "source": [
    "### 1 - Logistic Regression with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dcb22e-0c6b-4802-83a2-a707ea77102f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Import necessary classes for Logistic Regression, evaluation, and cross-validation\n",
    "\n",
    "\n",
    "# TODO: Initialize the Logistic Regression model\n",
    "\n",
    "\n",
    "# TODO: Perform cross-validation on Logistic Regression model\n",
    "\n",
    "\n",
    "# Print cross-validation scores and average accuracy\n",
    "print(\"Logistic Regression Cross-Validation Scores:\", log_reg_cv_scores)\n",
    "print(\"Average Cross-Validation Score:\", log_reg_cv_scores.mean())\n",
    "\n",
    "# Train and evaluate Logistic Regression on the test set\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "\n",
    "# Print Logistic Regression performance metrics\n",
    "print(\"Logistic Regression Performance on Test Set:\")\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "print(confusion_matrix(y_test, y_pred_log))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a61766-7f61-4d4e-ae9c-4de946fc7f6a",
   "metadata": {},
   "source": [
    "## 2 - Support Vector Machine (SVM) with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b8192e-7ab0-4899-9ba6-ba9c02b76d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import SVC from sklearn.svm\n",
    "\n",
    "\n",
    "# TODO: Initialize the SVM model with kernel='linear'\n",
    "\n",
    "\n",
    "# TODO: Perform cross-validation on the SVM model\n",
    "\n",
    "\n",
    "# Print cross-validation scores and average accuracy\n",
    "print(\"SVM Cross-Validation Scores:\", svm_cv_scores)\n",
    "print(\"Average Cross-Validation Score:\", svm_cv_scores.mean())\n",
    "\n",
    "# Train and evaluate SVM on the test set\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# Print SVM performance metrics\n",
    "print(\"SVM Performance on Test Set:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841bff85-28c1-429e-af37-60c2ed4973dd",
   "metadata": {},
   "source": [
    "## 3 - K-Nearest Neighbors (KNN) with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dc99dc-7cd6-4b52-8c6b-fb60eefb389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import KNeighborsClassifier from sklearn.neighbors\n",
    "\n",
    "\n",
    "# TODO: Initialize the KNN model with n_neighbors=5\n",
    "\n",
    "\n",
    "# TODO: Perform cross-validation on the KNN model\n",
    "\n",
    "\n",
    "# Print cross-validation scores and average accuracy\n",
    "print(\"KNN Cross-Validation Scores:\", knn_cv_scores)\n",
    "print(\"Average Cross-Validation Score:\", knn_cv_scores.mean())\n",
    "\n",
    "# Train and evaluate KNN on the test set\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Print KNN performance metrics\n",
    "print(\"KNN Performance on Test Set:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe4db42-6a13-4c91-b523-f86767869314",
   "metadata": {},
   "source": [
    "## 4 - Decision Tree with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6493a40d-5206-43da-a382-9ee87bceb9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import DecisionTreeClassifier from sklearn.tree\n",
    "\n",
    "\n",
    "# TODO: Initialize the Decision Tree model\n",
    "\n",
    "\n",
    "# TODO: Perform cross-validation on the Decision Tree model\n",
    "\n",
    "\n",
    "# Print cross-validation scores and average accuracy\n",
    "print(\"Decision Tree Cross-Validation Scores:\", dt_cv_scores)\n",
    "print(\"Average Cross-Validation Score:\", dt_cv_scores.mean())\n",
    "\n",
    "# Train and evaluate Decision Tree on the test set\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# Print Decision Tree performance metrics\n",
    "print(\"Decision Tree Performance on Test Set:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426d3ed1-7771-405e-aa20-fb55be26bbfd",
   "metadata": {},
   "source": [
    "## 5 - Random Forest with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e008ee1b-06ed-4d6f-8f1f-c09818f0bc9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Import RandomForestClassifier from sklearn.ensemble\n",
    "\n",
    "\n",
    "# TODO: Initialize the Random Forest model\n",
    "\n",
    "\n",
    "# TODO: Perform cross-validation on the Random Forest model\n",
    "\n",
    "\n",
    "# Print cross-validation scores and average accuracy\n",
    "print(\"Random Forest Cross-Validation Scores:\", rf_cv_scores)\n",
    "print(\"Average Cross-Validation Score:\", rf_cv_scores.mean())\n",
    "\n",
    "# Train and evaluate Random Forest on the test set\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Print Random Forest performance metrics\n",
    "print(\"Random Forest Performance on Test Set:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff67a20-9d6e-4908-842a-3ae3aa4707ef",
   "metadata": {},
   "source": [
    "## 6 - Gradient Boosting with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f900613-8fb5-4915-94a9-faf05c171ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Import GradientBoostingClassifier from sklearn.ensemble\n",
    "\n",
    "\n",
    "# TODO: Initialize the Gradient Boosting model\n",
    "\n",
    "\n",
    "# TODO: Perform cross-validation on the Gradient Boosting model\n",
    "\n",
    "\n",
    "# Print cross-validation scores and average accuracy\n",
    "print(\"Gradient Boosting Cross-Validation Scores:\", gb_cv_scores)\n",
    "print(\"Average Cross-Validation Score:\", gb_cv_scores.mean())\n",
    "\n",
    "# Train and evaluate Gradient Boosting on the test set\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "\n",
    "# Print Gradient Boosting performance metrics\n",
    "print(\"Gradient Boosting Performance on Test Set:\")\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd20dc71-1cdb-45b2-9696-574ac0461841",
   "metadata": {},
   "source": [
    "\n",
    "## Model Comparison and Conclusion\n",
    "\n",
    "Now that we have explored six classification algorithms, letâ€™s compare their performance using the cross-validation scores as well as the accuracy, precision, recall, and F1-score on the test set.\n",
    "\n",
    "Consider the stability and reliability of each model based on their cross-validation scores. Reflect on which models might be most suitable for predicting tumor malignancy and why, based on your observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc55a153-bf6b-4623-8e1f-82d4f36f76e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary library for DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary to hold the model names and their performance metrics\n",
    "model_results = {\n",
    "    \"Model\": [\"Logistic Regression\", \"SVM\", \"KNN\", \"Decision Tree\", \"Random Forest\", \"Gradient Boosting\"],\n",
    "    \"Avg. Cross-Validation Score\": [\n",
    "        log_reg_cv_scores.mean(), \n",
    "        svm_cv_scores.mean(), \n",
    "        knn_cv_scores.mean(), \n",
    "        dt_cv_scores.mean(), \n",
    "        rf_cv_scores.mean(), \n",
    "        gb_cv_scores.mean()\n",
    "    ],\n",
    "    \"Test Accuracy\": [\n",
    "        log_reg.score(X_test, y_test),\n",
    "        svm.score(X_test, y_test),\n",
    "        knn.score(X_test, y_test),\n",
    "        dt.score(X_test, y_test),\n",
    "        rf.score(X_test, y_test),\n",
    "        gb.score(X_test, y_test)\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        classification_report(y_test, y_pred_log, output_dict=True)['1']['precision'],\n",
    "        classification_report(y_test, y_pred_svm, output_dict=True)['1']['precision'],\n",
    "        classification_report(y_test, y_pred_knn, output_dict=True)['1']['precision'],\n",
    "        classification_report(y_test, y_pred_dt, output_dict=True)['1']['precision'],\n",
    "        classification_report(y_test, y_pred_rf, output_dict=True)['1']['precision'],\n",
    "        classification_report(y_test, y_pred_gb, output_dict=True)['1']['precision']\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        classification_report(y_test, y_pred_log, output_dict=True)['1']['recall'],\n",
    "        classification_report(y_test, y_pred_svm, output_dict=True)['1']['recall'],\n",
    "        classification_report(y_test, y_pred_knn, output_dict=True)['1']['recall'],\n",
    "        classification_report(y_test, y_pred_dt, output_dict=True)['1']['recall'],\n",
    "        classification_report(y_test, y_pred_rf, output_dict=True)['1']['recall'],\n",
    "        classification_report(y_test, y_pred_gb, output_dict=True)['1']['recall']\n",
    "    ],\n",
    "    \"F1-Score\": [\n",
    "        classification_report(y_test, y_pred_log, output_dict=True)['1']['f1-score'],\n",
    "        classification_report(y_test, y_pred_svm, output_dict=True)['1']['f1-score'],\n",
    "        classification_report(y_test, y_pred_knn, output_dict=True)['1']['f1-score'],\n",
    "        classification_report(y_test, y_pred_dt, output_dict=True)['1']['f1-score'],\n",
    "        classification_report(y_test, y_pred_rf, output_dict=True)['1']['f1-score'],\n",
    "        classification_report(y_test, y_pred_gb, output_dict=True)['1']['f1-score']\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame for easy visualization\n",
    "results_df = pd.DataFrame(model_results)\n",
    "\n",
    "# Display the table\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5f8b84-9c46-4e49-8d8a-e6d5a6e9c265",
   "metadata": {},
   "source": [
    "### Are the Results Robust?\n",
    "\n",
    "Consistency: If both cross-validation and test scores are high, this generally suggests a robust model. Consistency between cross-validation scores and test set performance indicates the model is not overfitting or underfitting, which is a positive sign for robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c3e163-578d-4c07-90b9-3fb7759bb787",
   "metadata": {},
   "source": [
    "In medical contexts, a slight preference might be given to models with higher recall (measures how well a model finds all the true positive cases.), even if it means a slight trade-off in precision. Missing a malignant tumor is often more serious than incorrectly identifying a benign tumor as malignant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
