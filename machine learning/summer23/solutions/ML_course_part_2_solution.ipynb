{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Handling Text\n",
        "Handling text in machine learning refers to the process of preparing and processing textual data to be used as input for machine learning algorithms. It involves various techniques and steps, including:\n",
        "\n",
        "1. Text Cleaning: This involves removing unwanted characters, punctuation, and special symbols from the text. It may also include tasks like lowercasing, stemming, and lemmatization to normalize the text.\n",
        "\n",
        "2. Tokenization: It is the process of breaking down the text into smaller units called tokens. Tokens can be words, phrases, or even individual characters, depending on the requirements.\n",
        "\n",
        "3. Stopword Removal: Stopwords are commonly used words (e.g., \"the,\" \"is,\" \"and\") that do not carry significant meaning. Removing stopwords helps reduce noise in the text data.\n",
        "\n",
        "4. Vectorization: Text data needs to be converted into numerical representations for machine learning algorithms to process. Common techniques for vectorization include bag-of-words (BoW), term frequency-inverse document frequency (TF-IDF), and word embeddings like Word2Vec or GloVe.\n",
        "\n",
        "5. Feature Engineering: It involves extracting additional features from text data that can enhance the performance of machine learning models. This may include features like word count, character count, n-grams, or sentiment analysis.\n",
        "\n",
        "6. Handling Imbalanced Text Data: In text classification tasks, it is common to have imbalanced classes where some categories have more samples than others. Techniques like oversampling, undersampling, or using class weights can be employed to address this issue.\n",
        "\n",
        "7. Model Selection and Evaluation: After preprocessing the text data, appropriate machine learning algorithms can be selected, such as Naive Bayes, Support Vector Machines (SVM), or Recurrent Neural Networks (RNNs). Model performance can be evaluated using metrics like accuracy, precision, recall, and F1 score.\n",
        "\n",
        "It's important to note that the specific steps and techniques used for handling text data can vary depending on the nature of the problem and the available resources."
      ],
      "metadata": {
        "id": "IQFIk5PnXbCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Textual Data\n",
        "Textual data can be categorised to rwo main differnet types: Structured Text and Unstructured Text.\n",
        "\n",
        "- **Structured Text**: Structured text typically follows a specific schema or template, making it easily readable and interpretable by machines. Examples of structured text include data stored in spreadsheets, databases, or CSV files.\n",
        "\n",
        "- **Unstructured Text**: Unstructured text, on the other hand, refers to text data that does not have a predefined structure or format. Examples of unstructured text include social media posts, emails, news articles, blog posts, and customer reviews."
      ],
      "metadata": {
        "id": "gf223bLyYv1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hands-On Exercises\n",
        "\n",
        "The exercises are from the [textbook](https://www.oreilly.com/library/view/machine-learning-with/9781491989371/)"
      ],
      "metadata": {
        "id": "QFAiqfSrZ6og"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Problem 1\n",
        "##1.1 Text Cleaning\n",
        "\n",
        "\n",
        "Most text data will need to be cleaned before we can use it to build features. Most basic text cleaning can be completed using Python’s standard string operations. In the real world we will most likely define a custom cleaning function (e.g., capitalizer) combining some cleaning tasks and apply that to the text data.\n",
        "\n",
        "In this problesm, we have some unstructured text data and want to complete some basic cleaning.\n"
      ],
      "metadata": {
        "id": "_AIDEGmbbNeM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovqJH3WUXMzd",
        "outputId": "aaee0050-6472-4e9f-be94-f4c7a4e9a52c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['   Interrobang. By Aishwarya Henriette     ',\n",
              " 'Parking And Going. By Karl Gautier',\n",
              " '    Today Is The night. By Jarek Prakash   ']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Create text\n",
        "text_data = [\"   Interrobang. By Aishwarya Henriette     \",\n",
        "                 \"Parking And Going. By Karl Gautier\",\n",
        "                 \"    Today Is The night. By Jarek Prakash   \"]\n",
        "\n",
        "# Show text\n",
        "text_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Strip whitespaces\n",
        "strip_whitespace = [string.strip() for string in text_data]\n",
        "\n",
        "# Show text\n",
        "strip_whitespace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qrb2EfN9cp4h",
        "outputId": "fd3fa2f1-2e4f-4094-8e27-8626e4ce6190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Interrobang. By Aishwarya Henriette',\n",
              " 'Parking And Going. By Karl Gautier',\n",
              " 'Today Is The night. By Jarek Prakash']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove periods\n",
        "remove_periods = [string.replace(\".\", \"\") for string in strip_whitespace]\n",
        "\n",
        "# Show text\n",
        "remove_periods"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deY0BouXc01V",
        "outputId": "0eaafbbb-ad2c-4557-880c-9fcaae3facb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Interrobang By Aishwarya Henriette',\n",
              " 'Parking And Going By Karl Gautier',\n",
              " 'Today Is The night By Jarek Prakash']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create and apply a custom transformation function:"
      ],
      "metadata": {
        "id": "Y-YWfZ7gdAze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function\n",
        "def capitalizer(string: str) -> str: return string.upper()"
      ],
      "metadata": {
        "id": "rjK5oBugdEJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply function\n",
        "[capitalizer(string) for string in remove_periods]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbOP9IIydKST",
        "outputId": "f40eb68a-ec95-41af-cef1-c89e22e55776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['INTERROBANG BY AISHWARYA HENRIETTE',\n",
              " 'PARKING AND GOING BY KARL GAUTIER',\n",
              " 'TODAY IS THE NIGHT BY JAREK PRAKASH']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use [regular expressions](http://bit.ly/2HTGZuu) to make powerful string operations.\n",
        "\n",
        "Regex, short for Regular Expression, is a sequence of characters that forms a search pattern. It is a powerful tool used for pattern matching and text manipulation in various programming languages. It allows you to search, match, and extract specific patterns of text based on predefined rules and symbols."
      ],
      "metadata": {
        "id": "EJRoUzyndCmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library\n",
        "import re\n",
        "\n",
        "# Create function\n",
        "def replace_letters_with_X(string: str) -> str: return re.sub(r\"[a-zA-Z]\", \"X\", string)\n",
        "\n",
        "# Apply function\n",
        "[replace_letters_with_X(string) for string in remove_periods]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GYgFfcrdSy8",
        "outputId": "e2d48f33-3e7a-421a-d357-270fbe02d4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['XXXXXXXXXXX XX XXXXXXXXX XXXXXXXXX',\n",
              " 'XXXXXXX XXX XXXXX XX XXXX XXXXXXX',\n",
              " 'XXXXX XX XXX XXXXX XX XXXXX XXXXXXX']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.2 Parsing and Cleaning HTML\n",
        "\n",
        "Suppose you have text data with `HTML` elements and want to extract just the text. You can use Beautiful `Soup`’s extensive set of options to parse and extract from `HTML`"
      ],
      "metadata": {
        "id": "SVv0JG4ze_UW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Create some HTML code\n",
        "html = \"\"\"\n",
        "           <div class='full_name'><span style='font-weight:bold'>\n",
        "           Masego</span> Azra</div>\"\n",
        "           \"\"\"\n",
        "\n",
        "#show html\n",
        "html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "KtGkz6lJfYGf",
        "outputId": "5faa6bb2-a332-4b34-e5a5-314efc9a51e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n           <div class=\\'full_name\\'><span style=\\'font-weight:bold\\'>\\n           Masego</span> Azra</div>\"\\n           '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite the strange name, [Beautiful Soup](http://bit.ly/2pwZcYs) is a powerful Python library designed for scraping HTML. Typically Beautiful Soup is used scrape live websites, but we can just as easily use it to extract text data embedded in HTML. The full range of Beautiful Soup operations is beyond the scope of this book, but even the few methods used in our solution show how easily we can parse HTML code to extract the data we want."
      ],
      "metadata": {
        "id": "qc9kn2mcf76o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse html\n",
        "soup = BeautifulSoup(html, \"lxml\")\n"
      ],
      "metadata": {
        "id": "orlO92zHfhGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the div with the class \"full_name\", show text\n",
        "soup.find(\"div\", { \"class\" : \"full_name\" }).text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "rBGHymRlfy8Z",
        "outputId": "3064c04e-3e10-4aa0-f64c-ac4dd69eb8c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n           Masego Azra'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.3 Removing Punctuation\n",
        "\n",
        "You have a feature of text data and want to remove punctuation."
      ],
      "metadata": {
        "id": "RbD2vouSgHIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import unicodedata\n",
        "import sys\n",
        "\n",
        "# Create text\n",
        "text_data = ['Hi!!!! I. Love. This. Song....',\n",
        "                 '10000% Agree!!!! #LoveIT',\n",
        "                 'Right?!?!']\n",
        "\n",
        "#show text\n",
        "text_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrU-So5jhVuU",
        "outputId": "cd31471c-3381-4af8-a57b-09dae8eecbe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi!!!! I. Love. This. Song....', '10000% Agree!!!! #LoveIT', 'Right?!?!']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of punctuation characters\n",
        "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
        "  if unicodedata.category(chr(i)).startswith('P'))\n"
      ],
      "metadata": {
        "id": "1mhKKum0hk_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For each string, remove any punctuation characters\n",
        "[string.translate(punctuation) for string in text_data]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oDZ4a1niFZ9",
        "outputId": "44a345ea-9a86-4cb2-8bfe-0e7e9c8618d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi I Love This Song', '10000 Agree LoveIT', 'Right']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion**\n",
        "\n",
        "The `translate` method in Python is widely used for its exceptional speed. In our approach, we started by constructing a dictionary called `punctuation` that contains all punctuation characters based on Unicode. We then used this dictionary to translate any characters in the string that match the punctuation characters into None, effectively eliminating them. While there are more readable methods to remove punctuation, this somewhat unconventional solution offers the advantage of significantly faster execution compared to alternative approaches."
      ],
      "metadata": {
        "id": "OsoMiXE4g1T5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.4 Tokenizing Text\n",
        "\n",
        "In this section of the problem we have text and want to break it up into individual words. We will use Natural Language Toolkit for Python (NLTK) which has a powerful set of text manipulation operations, including word tokenizing.\n",
        "\n",
        "Tokenization, particularly word tokenization, is a standard procedure performed after cleaning textual data. This step serves as the initial stage in converting the text into a structured format that can be utilized to create meaningful features."
      ],
      "metadata": {
        "id": "s-VhXrMMi1R2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Create text\n",
        "string = \"The science of today is the technology of tomorrow\"\n",
        "\n",
        "#show text\n",
        "string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "gRChmjxWjT8G",
        "outputId": "f046d90a-706b-4b04-c796-3c966bf65519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The science of today is the technology of tomorrow'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# punkt is a nltk library tool for tokenizing text documents.\n",
        "#When we use an old or a degraded version of nltk module we\n",
        "#generally need to download the remaining data .You can do:\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PDq5e-kjXYM",
        "outputId": "88a0ed93-798a-4e8b-97ef-a9db6b7fab4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Error loading corpus: Package 'corpus' not found in index\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'science', 'of', 'today', 'is', 'the', 'technology', 'of', 'tomorrow']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize words\n",
        "word_tokenize(string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gT1_YPCkPdr",
        "outputId": "64c339a8-c3f6-45ee-faa3-54c04e9ee3f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'science', 'of', 'today', 'is', 'the', 'technology', 'of', 'tomorrow']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also tokenize into sentences:"
      ],
      "metadata": {
        "id": "TlXvVYHCkXuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Create text\n",
        "string = \"The science of today is the technology of tomorrow. Tomorrow is today.\"\n",
        "\n",
        "# Tokenize sentences\n",
        "sent_tokenize(string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2MpJCChkaHF",
        "outputId": "1599ce01-034e-43ee-846b-443d7ea02b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The science of today is the technology of tomorrow.', 'Tomorrow is today.']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Removing Stop Words\n",
        "\n",
        "Given tokenized text data, you want to remove extremely common words (e.g., a, is, of, on) that contain little informational value.\n",
        "\n",
        "We use NLTK’s stopwords:"
      ],
      "metadata": {
        "id": "-05jFKTLkylI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# You will have to download the set of stop words the first time\n",
        "# import nltk\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHx5tLSOk7lV",
        "outputId": "022e40e2-683f-418f-d371-346b55dd935c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create word tokens\n",
        "tokenized_words = ['i',\n",
        "                       'am',\n",
        "                       'going',\n",
        "                       'to',\n",
        "                       'go',\n",
        "                       'to',\n",
        "                       'the',\n",
        "                       'store',\n",
        "                       'and',\n",
        "                       'park']\n",
        "\n",
        "#show text\n",
        "tokenized_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxep85f8lQXV",
        "outputId": "a8dcb4c7-6b4d-4bdc-d80f-15baa5517d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'am', 'going', 'to', 'go', 'to', 'the', 'store', 'and', 'park']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load stop words\n",
        "stop_words = stopwords.words('english')"
      ],
      "metadata": {
        "id": "4Xn-wGzIlgW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop words\n",
        "[word for word in tokenized_words if word not in stop_words]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfp9g2hdmDHL",
        "outputId": "cb8c4249-683d-4a56-dc27-afa230baf6af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['going', 'go', 'store', 'park']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion**\n",
        "\n",
        "While “stop words” can refer to any set of words we want to remove before process‐ ing, frequently the term refers to extremely common words that themselves contain little information value. NLTK has a list of common stop words that we can use to find and remove stop words in our tokenized words:"
      ],
      "metadata": {
        "id": "MVnJRrO6mKu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show stop words\n",
        "stop_words[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwGkb6ITmNqf",
        "outputId": "444d39cb-e08a-4e5f-eed0-a97dbe8281af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note** that NLTK’s stopwords assumes the tokenized words are all lowercased."
      ],
      "metadata": {
        "id": "NoF6KM6RmWIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.6 Stemming Words\n",
        "\n",
        "Stemming reduces a word to its stem by identifying and removing affixes (e.g., gerunds) while keeping the root meaning of the word. For example, both “tradition” and “traditional” have “tradit” as their stem, indicating that while they are different words they represent the same general concept. By stemming our text data, we transform it to something less readable, but closer to its base meaning and thus more suitable for comparison across observations. NLTK’s `PorterStemmer` implements the widely used [Porter stemming algorithm](http://bit.ly/2FB5ZZb) to remove or replace common suffixes to produce the word stem."
      ],
      "metadata": {
        "id": "4hHkgN-SmY7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have tokenized words and your task id to convert them into their root forms. You can use NLTK’s PorterStemmer:"
      ],
      "metadata": {
        "id": "9o29mft3nYiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "# Create word tokens\n",
        "tokenized_words = ['i', 'am', 'humbled', 'by', 'this', 'traditional', 'meeting']"
      ],
      "metadata": {
        "id": "Yz_3Im9fnQjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create stemmer\n",
        "porter = PorterStemmer()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PolzNAkdnoGn",
        "outputId": "fd9cf2a9-98b7-4b36-de48-69e38ceffa37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PorterStemmer>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply stemmer\n",
        "[porter.stem(word) for word in tokenized_words]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OMRuwSAnsxi",
        "outputId": "b9181480-f5a9-467b-8678-10443fffc693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'am', 'humbl', 'by', 'thi', 'tradit', 'meet']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.7 Tagging Parts of Speech\n",
        "Tagging parts of speech is the process of assigning grammatical labels or tags to words in a sentence based on their syntactic roles. It involves categorizing words into classes such as nouns, verbs, adjectives, adverbs, pronouns, prepositions, conjunctions, and more. Part-of-speech tagging helps in understanding the grammatical structure of a sentence and can be used as a preliminary step for various natural language processing tasks like text analysis, information retrieval, and machine translation.\n",
        "\n"
      ],
      "metadata": {
        "id": "qS6cJjmxoAvG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part of the text cleaning problem, you have text data and your task is to tag each word or character with its part of speech. To perform this task you can use NLTK’s pre-trained parts-of-speech tagger:"
      ],
      "metadata": {
        "id": "vVDBzprgohC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "from nltk import pos_tag\n",
        "from nltk import word_tokenize\n",
        "\n",
        "nltk.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "3bZrJ7GVo98k",
        "outputId": "58126b74-981c-4275-dcb4-c4485fd02489"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-97fa5cec369d>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error, print_error_to)\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdownload_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interactive_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_interactive_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m                 \u001b[0mDownloaderGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTclError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m                 \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0;34m\"q) Quit\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             )\n\u001b[0;32m-> 1141\u001b[0;31m             \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloader> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create text\n",
        "text_data = \"Chris loved outdoor running\""
      ],
      "metadata": {
        "id": "KqdV3_LRpBmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if run to error\n",
        "#nltk.download()"
      ],
      "metadata": {
        "id": "u4SYzUx1pX-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use pre-trained part of speech tagger\n",
        "text_tagged = pos_tag(word_tokenize(text_data))"
      ],
      "metadata": {
        "id": "aaet04HcpFms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output is a list of tuples with the word and the tag of the part of speech. NLTK uses the [Penn Treebank](http://bit.ly/2HROPo5) parts for speech tags. Some examples of the Penn Treebank tags are:\n",
        "\n",
        "**Tag Part of speech**\n",
        "\n",
        "NNP Proper noun, singular\n",
        "\n",
        "NN Noun, singular or mass\n",
        "\n",
        "RB Adverb\n",
        "\n",
        "VBD Verb, past tense\n",
        "\n",
        "VBG Verb, gerund or present participle\n",
        "\n",
        "JJ Adjective\n",
        "\n",
        "\n",
        "PRP Personal pronoun"
      ],
      "metadata": {
        "id": "wQIkm32gptQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show parts of speech\n",
        "text_tagged"
      ],
      "metadata": {
        "id": "7nPEWF6YplnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the text has been tagged, we can use the tags to find certain parts of speech. For example, here are all nouns:"
      ],
      "metadata": {
        "id": "3DRK53JxqFfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter words\n",
        "[word for word, tag in text_tagged if tag in ['NN','NNS','NNP','NNPS'] ]"
      ],
      "metadata": {
        "id": "KLwQYVdNqGa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.8 Encoding Text as a Bag of Words\n",
        "\n",
        "In this part, suppose you have text data and want to create a set of features indicating the number of times an observation’s text contains a particular word. You can use scikit-learn’s `CountVectorizer`:"
      ],
      "metadata": {
        "id": "t3mRlqSirRDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "DKsIBsSWrkQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create text\n",
        "text_data = np.array(['I love Brazil. Brazil!',\n",
        "                          'Sweden is best',\n",
        "                          'Germany beats both'])"
      ],
      "metadata": {
        "id": "Ncc0WK7brtWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the bag of words feature matrix\n",
        "count = CountVectorizer()\n",
        "bag_of_words = count.fit_transform(text_data)\n",
        "\n",
        "bag_of_words"
      ],
      "metadata": {
        "id": "7ZFcnYEurxhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting output is a sparse array, which is commonly used when dealing with a large volume of text data. In our simplified example, we can convert it to a dense array using the `toarray` function to obtain a matrix representing the count of words for each observation."
      ],
      "metadata": {
        "id": "HfBUx1Tir8dU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_of_words.toarray()"
      ],
      "metadata": {
        "id": "ru8nvhDFr34h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By utilizing the `vocabulary_` method, we can access the corresponding word for each feature in the dataset."
      ],
      "metadata": {
        "id": "pToJ6NHVsQfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show feature names\n",
        "count.get_feature_names()"
      ],
      "metadata": {
        "id": "ZJleCrQ8sRhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To provide clarity, let's take a look at the feature matrix where the column names represent the words. Each row in the matrix corresponds to a single observation.\n"
      ],
      "metadata": {
        "id": "EWC12zFLscSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "iFgzt1oksxhB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion**\n",
        "\n",
        "A commonly used technique for converting text into features is the bag-of-words model. This model assigns a feature to each unique word in the text data and counts the number of occurrences of each word in each observation. For instance, in our solution, the sentence \"I love Brazil. Brazil!\" would have a count of 2 for the feature \"brazil\" since the word \"brazil\" appears twice.\n"
      ],
      "metadata": {
        "id": "tfIEfXoxszj0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.9 Weighting Word Importance\n",
        "Suppose we want a bag of words, but with words weighted by their importance to an observation.\n",
        "\n",
        "Compare the frequency of the word in a document (a tweet, movie review, speech transcript, etc.) with the frequency of the word in all other documents using term frequency-inverse document frequency (tf-idf). scikit-learn makes this easy with TfidfVectorizer:"
      ],
      "metadata": {
        "id": "sy2Uia_Wucyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "4s4OgAjfvBNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create text\n",
        "text_data = np.array(['I love Brazil. Brazil!',\n",
        "                          'Sweden is best',\n",
        "                          'Germany beats both'])\n"
      ],
      "metadata": {
        "id": "o0_f0ryqvJFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the tf-idf feature matrix\n",
        "tfidf = TfidfVectorizer()\n",
        "feature_matrix = tfidf.fit_transform(text_data)"
      ],
      "metadata": {
        "id": "8ny-y5zBvTGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show tf-idf feature matrix\n",
        "feature_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1MQseARvYg1",
        "outputId": "f6309ed9-892f-4f9a-b3c3-b7fade933f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3x8 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 8 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show tf-idf feature matrix as dense matrix\n",
        "feature_matrix.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSPF_VJCvi7b",
        "outputId": "33398087-5d12-4918-ff1d-f4442acf1a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.89442719, 0.        ,\n",
              "        0.        , 0.4472136 , 0.        ],\n",
              "       [0.        , 0.57735027, 0.        , 0.        , 0.        ,\n",
              "        0.57735027, 0.        , 0.57735027],\n",
              "       [0.57735027, 0.        , 0.57735027, 0.        , 0.57735027,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`vocabulary_` shows us the word of each feature:"
      ],
      "metadata": {
        "id": "86yTDFgmvouO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show feature names\n",
        "tfidf.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AJ_ZDLfvqrB",
        "outputId": "e7900b7a-963f-48ef-ba48-adc4bbe2569b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'love': 6,\n",
              " 'brazil': 3,\n",
              " 'sweden': 7,\n",
              " 'is': 5,\n",
              " 'best': 1,\n",
              " 'germany': 4,\n",
              " 'beats': 0,\n",
              " 'both': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion**\n",
        "\n",
        "The more a word appears in a document, the more likely it is important to that document. For example, if the word economy appears frequently, it is evidence that the document might be about economics. We call this term frequency (*tf*).\n",
        "In contrast, if a word appears in many documents, it is likely less important to any individual document. For example, if every document in some text data contains the word after then it is probably an unimportant word. We call this document frequency (*df*).\n",
        "\n",
        "By combining these two statistics, we can assign a score to every word representing how important that word is in a document. Specifically, we multiply tf to the inverse of document frequency (*idf*):\n",
        "\n",
        "*tf‐idf (t,d) =tf (t,d) ×idf (t)*\n",
        "\n",
        "where *t* is a word and *d* is a document.\n"
      ],
      "metadata": {
        "id": "z1rGizuQv_PH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RCmUz6GVwOzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Problem 2\n",
        "##Handling Images\n",
        "Image classification is a fascinating field in machine learning that enables computers to identify patterns and objects in images. Before applying machine learning algorithms to images, we typically need to preprocess the raw images and convert them into usable features. The widely used Open Source Computer Vision Library (OpenCV) is a powerful tool for handling images, offering extensive documentation and popularity among developers."
      ],
      "metadata": {
        "id": "IbvW1aRMyHXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The book will use a set of images as examples, which are available to download on [GitHub](https://github.com/chrisalbon/simulated_datasets)."
      ],
      "metadata": {
        "id": "xTQDcUD4ym_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Loading Images\n",
        "Let's load an image for preprocessing. We use use OpenCV’s `imread`:"
      ],
      "metadata": {
        "id": "zHDxJPqTzWF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "2mppcWPhy3B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image as grayscale\n",
        "image = cv2.imread(\"./data/dataset-cover.jpg  \", cv2.IMREAD_GRAYSCALE)"
      ],
      "metadata": {
        "id": "-UkI8A6GCWgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to view the image, we can use the Python plotting library Matplotlib:"
      ],
      "metadata": {
        "id": "H-iVNZ1BCbYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show image\n",
        "plt.imshow(image, cmap=\"gray\"), plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "PbABrS6rCcR-",
        "outputId": "2278fab4-2065-49ae-dd12-5471b83e04ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-f8c495533c13>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Show image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0minterpolation_stage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         resample=None, url=None, data=None, **kwargs):\n\u001b[0;32m-> 2695\u001b[0;31m     __ret = gca().imshow(\n\u001b[0m\u001b[1;32m   2696\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5663\u001b[0m                               **kwargs)\n\u001b[1;32m   5664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5665\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5666\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    699\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[1;32m    700\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[0;32m--> 701\u001b[0;31m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[0m\u001b[1;32m    702\u001b[0m                             \"float\".format(self._A.dtype))\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fundamentally, images are data and when we use imread we convert that data into a data type we are very familiar with—a NumPy array:"
      ],
      "metadata": {
        "id": "RxRewrzdDyhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show data type\n",
        "type(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A78H7_kD0jo",
        "outputId": "6023b222-0c4a-4ddb-a5c6-ee3bb1d20104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have transformed the image into a matrix whose elements correspond to individ‐ ual pixels. We can even take a look at the actual values of the matrix:"
      ],
      "metadata": {
        "id": "d5z5NjBtFK-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show image data\n",
        "image"
      ],
      "metadata": {
        "id": "e3_t5HQqFMxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resolution of our image was 3600 × 2270, the exact dimensions of our matrix:"
      ],
      "metadata": {
        "id": "-62oA_RjFWi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show dimensions\n",
        "image.shape"
      ],
      "metadata": {
        "id": "vJWupMX_FYmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What does each element in the matrix actually represent? In grayscale images, the value of an individual element is the pixel intensity. Intensity values range from black (0) to white (255). For example, the intensity of the top-rightmost pixel in our image has a value of 140:"
      ],
      "metadata": {
        "id": "nMAO8AhZGj3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show first pixel\n",
        "image[0,0]"
      ],
      "metadata": {
        "id": "cRxKUFq9GjZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the matrix, each element contains three values corresponding to blue, green, red values (BGR):"
      ],
      "metadata": {
        "id": "3sfRepGbHZTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image in color\n",
        "image_bgr = cv2.imread(\"./data/dataset-cover.jpg\", cv2.IMREAD_COLOR)\n",
        "\n",
        "# Show pixel\n",
        "image_bgr[0,0]"
      ],
      "metadata": {
        "id": "miozbum2HaKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One small caveat: by default OpenCV uses BGR, but many image applications— including Matplotlib—use red, green, blue (RGB), meaning the red and the blue values are swapped. To properly display OpenCV color images in Matplotlib, we need to first convert the color to [RGB](http://bit.ly/2FxZjKZ) (apologies to hardcopy readers):"
      ],
      "metadata": {
        "id": "bLtd_t77HlWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to RGB\n",
        "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Show image\n",
        "plt.imshow(image_rgb), plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zRncCE6hHrif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Saving Images\n",
        "In this part, your task is to save an image for preprocessing. You can use OpenCV’s imwrite.\n",
        "\n",
        "Using OpenCV's `imwrite` function allows us to save images to a specified file path. The image format is determined by the extension of the filename (e.g., .*jpg*, .*png*). It is important to note that `imwrite` will overwrite existing files without displaying an error message or requesting confirmation, so caution should be exercised when using this function."
      ],
      "metadata": {
        "id": "K8PWuccLIDPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "# Load image as grayscale\n",
        "image = cv2.imread(\"../data/plane.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Save image\n",
        "cv2.imwrite(\"./data/plane_new.jpg\", image)"
      ],
      "metadata": {
        "id": "BBi7x08nIZWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Resizing Images\n",
        "Resizing images is a common preprocessing task in machine learning to ensure consistent dimensions and reduce memory usage. However, it can result in information loss as the image matrix is reduced in size. Common image sizes for machine learning include 32x32, 64x64, 96x96, and 256x256.\n",
        "\n",
        "In this task we want to resize an image for further preprocessing, we can use `resize` to change the size of an image:"
      ],
      "metadata": {
        "id": "hD-aBMsgI35H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "5OYbCx50J-Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image as grayscale\n",
        "image = cv2.imread(\"./data/plane.jpg\", cv2.IMREAD_GRAYSCALE)"
      ],
      "metadata": {
        "id": "Eh5kdYxzKBku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize image to 50 pixels by 50 pixels\n",
        "image_50x50 = cv2.resize(image, (50, 50))"
      ],
      "metadata": {
        "id": "Y4tMqyWoKFrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View image\n",
        "plt.imshow(image_50x50, cmap=\"gray\"), plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tHhXvSNLKL8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Cropping Images\n",
        "\n",
        "In OpenCV, image cropping is performed by selecting specific rows and columns from the image matrix. This allows us to keep only the desired portion of the image. Cropping is beneficial when we want to focus on a specific area of interest in every image, such as in the case of stationary security camera footage.\n",
        "\n",
        "For this task, we want to remove the outer portion of the image to change its dimensions.\n",
        "\n",
        "Solution: The image is encoded as a two-dimensional NumPy array, so we can crop the image easily by slicing the array:"
      ],
      "metadata": {
        "id": "0ezpnoHXKxc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "Vu9lrH1fLSWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image in grayscale\n",
        "image = cv2.imread(\"./data/plane.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Select first half of the columns and all rows\n",
        "image_cropped = image[:,:128]"
      ],
      "metadata": {
        "id": "Drw58oa1MMCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show image\n",
        "plt.imshow(image_cropped, cmap=\"gray\"), plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "evVVDJykMS2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Blurring Images\n",
        "In this section your task is to smooth out an image.\n",
        "\n",
        "To achieve image blurring, the average value of neighboring pixels is calculated and assigned to each pixel. This process involves using a mathematical representation called a kernel, which defines the neighboring pixels and the specific operation performed. The size of the kernel determines the extent of blurring, with larger kernels resulting in smoother images. In this example, we apply blurring by averaging the values within a 5 × 5 kernel surrounding each pixel."
      ],
      "metadata": {
        "id": "ymVjE632Mp1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Load image as grayscale\n",
        "image = cv2.imread(\"./data/plane.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Blur image\n",
        "image_blurry = cv2.blur(image, (5,5))\n",
        "\n",
        "# Show image\n",
        "plt.imshow(image_blurry, cmap=\"gray\"), plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yV1qnk7MNINc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To highlight the effect of kernel size, here is the same blurring with a 100 × 100 kernel:"
      ],
      "metadata": {
        "id": "99kgVDXSObfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Blur image\n",
        "image_very_blurry = cv2.blur(image, (100,100))\n",
        "\n",
        "# Show image\n",
        "plt.imshow(image_very_blurry, cmap=\"gray\"), plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3e4Mnvy8OcnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6 Sharpening Images\n",
        "Sharpening operates in a similar manner to blurring, but with the intention of enhancing image details instead of reducing them. Instead of using a kernel to average neighboring values, a specialized kernel is created to emphasize the central pixel. This process enhances the contrast of edges, making them more pronounced in the image.\n",
        "\n",
        "To perform the task of sharpening an image, create a kernel that highlights the target pixel. Then apply it to the image using fil ter2D:"
      ],
      "metadata": {
        "id": "RcRejcovOmsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "hox1TOSJPC7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image as grayscale\n",
        "image = cv2.imread(\"./data/plane.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Create kernel\n",
        "kernel = np.array([[0, -1, 0],\n",
        "                   [-1, 5,-1],\n",
        "                   [0, -1, 0]])"
      ],
      "metadata": {
        "id": "KmJqkZ2lPELw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sharpen image\n",
        "image_sharp = cv2.filter2D(image, -1, kernel)\n",
        "\n",
        "# Show image\n",
        "plt.imshow(image_sharp, cmap=\"gray\"), plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jF210jsOPMLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.7 Enhancing Contrast\n",
        "\n",
        "Your task is to increase the contrast between pixels in an image.\n",
        "\n",
        "Histogram equalization is an image processing technique that enhances the visibility of objects and shapes. When working with grayscale images, we can directly apply OpenCV's \"equalizeHist\" function to the image to achieve this effect."
      ],
      "metadata": {
        "id": "toyl7bUYPXIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Load image\n",
        "image = cv2.imread(\"./data/plane.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Enhance image\n",
        "image_enhanced = cv2.equalizeHist(image)\n",
        "\n",
        "# Show image\n",
        "plt.imshow(image_enhanced, cmap=\"gray\"), plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XIJ3eIHJPxck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the case of a color image, it is necessary to convert the image to the YUV color format. The Y component represents the brightness or luma, while the U and V components represent the color information. Once the conversion is done, we can apply the equalizeHist function to the image and then convert it back to the BGR or RGB color format."
      ],
      "metadata": {
        "id": "Q3pOY3KOQC59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image\n",
        "image_bgr = cv2.imread(\"./data/plane.jpg\")\n",
        "\n",
        "# Convert to YUV\n",
        "image_yuv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2YUV)\n",
        "\n",
        "# Apply histogram equalization\n",
        "image_yuv[:, :, 0] = cv2.equalizeHist(image_yuv[:, :, 0])\n",
        "\n",
        "# Convert to RGB\n",
        "image_rgb = cv2.cvtColor(image_yuv, cv2.COLOR_YUV2RGB)\n",
        "\n",
        "# Show image\n",
        "plt.imshow(image_rgb), plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-RekLZTuQEyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.8 Isolating Colors\n",
        "\n",
        "To isolate a color in an image, define a range of colors and then apply a mask to the image:"
      ],
      "metadata": {
        "id": "H_cVABXlQQNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Load image\n",
        "image_bgr = cv2.imread('./data/plane.jpg')\n",
        "\n",
        "# Convert BGR to HSV\n",
        "image_hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# Define range of blue values in HSV\n",
        "lower_blue = np.array([50,100,50])\n",
        "upper_blue = np.array([130,255,255])\n",
        "\n",
        "# Create mask\n",
        "mask = cv2.inRange(image_hsv, lower_blue, upper_blue)\n",
        "\n",
        "# Mask image\n",
        "image_bgr_masked = cv2.bitwise_and(image_bgr, image_bgr, mask=mask)\n",
        "\n",
        "# Convert BGR to RGB\n",
        "image_rgb = cv2.cvtColor(image_bgr_masked, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Show image\n",
        "plt.imshow(image_rgb), plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZrsXMx6zQdga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we create a mask for the image (we will only keep the white areas):\n",
        "# Show image\n",
        "plt.imshow(mask, cmap='gray'), plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OI_9d0WuQzuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.9 Binarizing Images\n",
        "\n",
        "\n",
        "Binarizing images in machine learning refers to the process of converting grayscale or color images into binary images, where each pixel is assigned either a black or white value. This is typically done by applying a thresholding technique.\n",
        "\n",
        "Thresholding is a technique used to convert pixel intensities above a certain value to white and those below the value to black. Adaptive thresholding is a more advanced method where the threshold value for a pixel is determined based on the intensities of its neighboring pixels. This approach is particularly useful in situations where lighting conditions vary across different areas of an image."
      ],
      "metadata": {
        "id": "-YCsdAVMRFBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Load image as grayscale\n",
        "image_grey = cv2.imread(\"./data/plane.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Apply adaptive thresholding\n",
        "max_output_value = 255\n",
        "neighborhood_size = 99\n",
        "subtract_from_mean = 10\n",
        "image_binarized = cv2.adaptiveThreshold(image_grey,\n",
        "                                            max_output_value,\n",
        "                                            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                            cv2.THRESH_BINARY,\n",
        "\n",
        "                                            neighborhood_size,\n",
        "                                            subtract_from_mean)\n",
        "\n",
        "# Show image\n",
        "plt.imshow(image_binarized, cmap=\"gray\"), plt.axis(\"on\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cMKGLHIZReJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.10 Removing Backgrounds\n",
        "\n",
        "In this part of the image handling problem your task is to isolate the foreground of an image.\n",
        "To perfom this,  you need to mark a rectangle around the desired foreground, then run the GrabCut algorithm:"
      ],
      "metadata": {
        "id": "cDWyYZNpR0Lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "5fkSbctESK-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image and convert to RGB\n",
        "image_bgr = cv2.imread('./data/plane.jpg')\n",
        "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Rectangle values: start x, start y, width, height\n",
        "rectangle = (250, 0, 1256, 1256)\n",
        "\n",
        "# Create initial mask\n",
        "mask = np.zeros(image_rgb.shape[:2], np.uint8)\n",
        "\n",
        "# Create temporary arrays used by grabCut\n",
        "bgdModel = np.zeros((1, 65), np.float64)\n",
        "fgdModel = np.zeros((1, 65), np.float64)\n",
        "\n",
        "# Run grabCut\n",
        "cv2.grabCut(image_rgb,              # Our image\n",
        "            mask,                   # The Mask\n",
        "            rectangle,              # Our rectangle\n",
        "            bgdModel,               # Temporary array for background\n",
        "            fgdModel,               # Temporary array for background\n",
        "            5,                      # Number of iterations\n",
        "            cv2.GC_INIT_WITH_RECT)  # Initiative using our rectangle\n",
        "\n",
        "# Create mask where sure and likely backgrounds set to 0, otherwise 1\n",
        "mask_2 = np.where((mask==2) | (mask==0), 0, 1).astype('uint8')\n",
        "\n",
        "# Multiply image with new mask to subtract background\n",
        "image_rgb_nobg = image_rgb * mask_2[:, :, np.newaxis]\n",
        "\n",
        "# Show image\n",
        "plt.imshow(image_rgb_nobg), plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gk1Zsa-xSOsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show mask\n",
        "plt.imshow(mask, cmap='gray'), plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EBMVB0oZSprN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show mask\n",
        "plt.imshow(mask_2, cmap='gray'), plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZUB7sdGfSzUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.11 Detecting Edges\n",
        "\n",
        "Edge detection is a prominent area of focus in computer vision, aiming to identify boundaries between objects in an image. These boundaries, or edges, carry significant information as they represent areas of high contrast or changes in intensity. By detecting edges, we can distinguish important features from less informative regions, such as homogeneous backgrounds. Various techniques exist for edge detection, including Sobel filters and the Laplacian edge detector, each offering different approaches to highlight these informative boundaries.\n",
        "\n",
        "In this part of the problem, we use an edge detection technique like the Canny edge detector to find the edges in an image:"
      ],
      "metadata": {
        "id": "zSLYfZ_IS4Jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Load image as grayscale\n",
        "image_gray = cv2.imread(\"./data/plane.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Calculate median intensity\n",
        "median_intensity = np.median(image_gray)\n",
        "\n",
        "# Set thresholds to be one standard deviation above and below median intensity\n",
        "lower_threshold = int(max(0, (1.0 - 0.33) * median_intensity))\n",
        "upper_threshold = int(min(255, (1.0 + 0.33) * median_intensity))\n",
        "\n",
        "# Apply canny edge detector\n",
        "image_canny = cv2.Canny(image_gray, lower_threshold, upper_threshold)\n",
        "\n",
        "# Show image\n",
        "plt.imshow(image_canny, cmap=\"gray\"), plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D86kprx3TEMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.12 Detecting Corners\n",
        "\n",
        "To detect the corners of an image, we use OpenCV’s implementation of the Harris corner detector, cornerHarris.\n",
        "\n",
        "The Harris corner detector is a widely used technique for identifying corner points, which are regions of high information in an image. It operates by examining windows or patches of pixels and detecting significant changes in their content when the window is slightly moved. The cornerHarris function, used for this purpose, has three important parameters: `block_size` determines the size of the neighboring region for corner detection, `aperture` refers to the size of the Sobel kernel used, and a free parameter controls the sensitivity for detecting corners, with larger values indicating softer corners."
      ],
      "metadata": {
        "id": "lYTop5SRTzeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Load image as grayscale\n",
        "image_bgr = cv2.imread(\"./data/plane.jpg\")\n",
        "image_gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
        "image_gray = np.float32(image_gray)\n",
        "\n",
        "# Set corner detector parameters\n",
        "block_size = 2\n",
        "aperture = 29\n",
        "free_parameter = 0.04\n",
        "\n",
        "# Detect corners\n",
        "detector_responses = cv2.cornerHarris(image_gray,\n",
        "                                          block_size,\n",
        "                                          aperture,\n",
        "                                          free_parameter)\n",
        "# Large corner markers\n",
        "detector_responses = cv2.dilate(detector_responses, None)\n",
        "\n",
        "# Only keep detector responses greater than threshold, mark as white\n",
        "threshold = 0.02\n",
        "image_bgr[detector_responses >\n",
        "              threshold *\n",
        "              detector_responses.max()] = [255,255,255]\n",
        "\n",
        "# Convert to grayscale\n",
        "image_gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Show image\n",
        "plt.imshow(image_gray, cmap=\"gray\"), plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "d78L5X8PUNMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.13 Creating Features for Machine Learning\n",
        "\n",
        "You want to convert an image into an observation for machine learning. To do so, use NumPy’s flatten to convert the multidimensional array containing an image’s data into a vector containing the observation’s values:"
      ],
      "metadata": {
        "id": "DGTtDYiiU8rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load image\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Load image as grayscale\n",
        "image = cv2.imread(\"./data/plane.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Resize image to 10 pixels by 10 pixels\n",
        "image_10x10 = cv2.resize(image, (10, 10))\n",
        "\n",
        "# Convert image data to one-dimensional vector\n",
        "image_10x10.flatten()"
      ],
      "metadata": {
        "id": "VnC-dQa3VVLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion**\n",
        "\n",
        "Images are presented as a grid of pixels. If an image is in grayscale, each pixel is pre‐ sented by one value (i.e., pixel intensity: 1 if white, 0 if black). For example, imagine we have a 10 × 10–pixel image:"
      ],
      "metadata": {
        "id": "NciC_IFCVdfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image_10x10, cmap=\"gray\"), plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gU--3P1NVepR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case the dimensions of the images data will be 10 × 10:"
      ],
      "metadata": {
        "id": "pll61hOgVnex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_10x10.shape"
      ],
      "metadata": {
        "id": "Qyh7iaDHVoO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And if we flatten the array, we get a vector of length 100 (10 multiplied by 10):"
      ],
      "metadata": {
        "id": "c5No9OE_VqHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_10x10.flatten().shape"
      ],
      "metadata": {
        "id": "Mcpe5YAwVt4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the feature data for our image that can be joined with the vectors from other images to create the data we will feed to our machine learning algorithms."
      ],
      "metadata": {
        "id": "Ht34z4RcVz3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the image is in color, instead of each pixel being represented by one value, it is rep‐ resented by multiple values (most often three) representing the channels (red, green, blue, etc.) that blend to make the final color of that pixel. For this reason, if our 10 × 10 image is in color, we will have 300 feature values for each observation:"
      ],
      "metadata": {
        "id": "pwE_bsThV-Wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image in color\n",
        "image_color = cv2.imread(\"./data/plane.jpg\", cv2.IMREAD_COLOR)\n",
        "\n",
        "# Resize image to 10 pixels by 10 pixels\n",
        "image_color_10x10 = cv2.resize(image_color, (10, 10))\n",
        "\n",
        "# Convert image data to one-dimensional vector, show dimensions\n",
        "image_color_10x10.flatten().shape"
      ],
      "metadata": {
        "id": "oENmYS6hWB1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the major challenges of image processing and computer vision is that since every pixel location in a collection of images is a feature, as the images get larger, the number of features explodes"
      ],
      "metadata": {
        "id": "FTCzaUf4WMch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image in grayscale\n",
        "image_256x256_gray = cv2.imread(\"./data/plane.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Convert image data to one-dimensional vector, show dimensions\n",
        "image_256x256_gray.flatten().shape"
      ],
      "metadata": {
        "id": "SwYQWeRDWMs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And the number of features only intensifies when the image is in color:"
      ],
      "metadata": {
        "id": "2Kr9BFDdWUjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image in color\n",
        "image_256x256_color = cv2.imread(\"./data/plane.jpg\", cv2.IMREAD_COLOR)\n",
        "\n",
        "# Convert image data to one-dimensional vector, show dimensions\n",
        "image_256x256_color.flatten().shape"
      ],
      "metadata": {
        "id": "SUDxSIWFWYIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As demonstrated in the output, a compact color image already encompasses approximately 200,000 features. This can pose challenges during model training since the number of features may greatly surpass the number of observations available, leading to potential issues."
      ],
      "metadata": {
        "id": "2LIFIX3-WhfM"
      }
    }
  ]
}