{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d022b1f-f0bf-453e-8417-3b92de7c9c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c88f4fc2-024d-4370-b417-4ece6aedc385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "439761d6-76e0-44d9-85b1-2bbf755b7f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plain_text']\n"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "configs = get_dataset_config_names(\"imdb\")\n",
    "print(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b4cb192-9a44-43a5-a7df-1fe6c3258aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/omranian/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298fb726c7df460fb578245cc7d99174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = load_dataset('imdb','plain_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "636b4e05-4880-4994-a728-c7587591951a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfa58b31-2368-4fb7-ade9-e928e13f6c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>A hit at the time but now better categorised a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>I love this movie like no other. Another time ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>This film and it's sequel Barry Mckenzie holds...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>'The Adventures Of Barry McKenzie' started lif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>The story centers around Barry McKenzie who mu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1      \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2      If only to avoid making this type of film in t...      0\n",
       "3      This film was probably inspired by Godard's Ma...      0\n",
       "4      Oh, brother...after hearing about this ridicul...      0\n",
       "...                                                  ...    ...\n",
       "24995  A hit at the time but now better categorised a...      1\n",
       "24996  I love this movie like no other. Another time ...      1\n",
       "24997  This film and it's sequel Barry Mckenzie holds...      1\n",
       "24998  'The Adventures Of Barry McKenzie' started lif...      1\n",
       "24999  The story centers around Barry McKenzie who mu...      1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = datasets['train'].to_pandas()\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cfe2498-8e9d-4b1c-8b59-e0605c943b59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love sci-fi and am willing to put up with a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worth the entertainment value of a rental, esp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its a totally average film with a few semi-alr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STAR RATING: ***** Saturday Night **** Friday ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First off let me say, If you haven't enjoyed a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>Just got around to seeing Monster Man yesterda...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>I got this as part of a competition prize. I w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>I got Monster Man in a box set of three films ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>Five minutes in, i started to feel how naff th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>I caught this movie on the Sci-Fi channel rece...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      I love sci-fi and am willing to put up with a ...      0\n",
       "1      Worth the entertainment value of a rental, esp...      0\n",
       "2      its a totally average film with a few semi-alr...      0\n",
       "3      STAR RATING: ***** Saturday Night **** Friday ...      0\n",
       "4      First off let me say, If you haven't enjoyed a...      0\n",
       "...                                                  ...    ...\n",
       "24995  Just got around to seeing Monster Man yesterda...      1\n",
       "24996  I got this as part of a competition prize. I w...      1\n",
       "24997  I got Monster Man in a box set of three films ...      1\n",
       "24998  Five minutes in, i started to feel how naff th...      1\n",
       "24999  I caught this movie on the Sci-Fi channel rece...      1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = datasets['test'].to_pandas()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65aeedd7-b5c5-4db6-9855-297626c87fed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        I rented I AM CURIOUS-YELLOW from my video sto...\n",
       "1        \"I Am Curious: Yellow\" is a risible and preten...\n",
       "2        If only to avoid making this type of film in t...\n",
       "3        This film was probably inspired by Godard's Ma...\n",
       "4        Oh, brother...after hearing about this ridicul...\n",
       "                               ...                        \n",
       "24995    A hit at the time but now better categorised a...\n",
       "24996    I love this movie like no other. Another time ...\n",
       "24997    This film and it's sequel Barry Mckenzie holds...\n",
       "24998    'The Adventures Of Barry McKenzie' started lif...\n",
       "24999    The story centers around Barry McKenzie who mu...\n",
       "Name: text, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38a70140-969c-49f3-b130-79ecd76e53e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn\\'t match the background, and painfully one-dimensional characters cannot be overcome with a \\'sci-fi\\' setting. (I\\'m sure there are those of you out there who think Babylon 5 is good sci-fi TV. It\\'s not. It\\'s clichéd and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It\\'s really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it\\'s rubbish as they have to always say \"Gene Roddenberry\\'s Earth...\" otherwise people would not continue watching. Roddenberry\\'s ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ecb2dbe-2d36-4b8c-afdd-ad84b61f1184",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/omranian/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd5d60f3-4bf7-49f1-963f-c2b120eeb491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to clean data\n",
    "import string\n",
    "import itertools \n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stops = ['the','a','an','and','but','if','or','because','as','what','which','this','that','these','those','then',\n",
    "              'just','so','than','such','both','through','about','for','is','of','while','during','to','What','Which',\n",
    "              'Is','If','While','This']\n",
    "\n",
    "def cleanData(text, lowercase = False, remove_stops = False, stemming = False, lemmatization = False):\n",
    "    txt = str(text)\n",
    "    \n",
    "    # Replace apostrophes with standard lexicons\n",
    "    txt = txt.replace(\"isn't\", \"is not\")\n",
    "    txt = txt.replace(\"aren't\", \"are not\")\n",
    "    txt = txt.replace(\"ain't\", \"am not\")\n",
    "    txt = txt.replace(\"won't\", \"will not\")\n",
    "    txt = txt.replace(\"didn't\", \"did not\")\n",
    "    txt = txt.replace(\"shan't\", \"shall not\")\n",
    "    txt = txt.replace(\"haven't\", \"have not\")\n",
    "    txt = txt.replace(\"hadn't\", \"had not\")\n",
    "    txt = txt.replace(\"hasn't\", \"has not\")\n",
    "    txt = txt.replace(\"don't\", \"do not\")\n",
    "    txt = txt.replace(\"wasn't\", \"was not\")\n",
    "    txt = txt.replace(\"weren't\", \"were not\")\n",
    "    txt = txt.replace(\"doesn't\", \"does not\")\n",
    "    txt = txt.replace(\"'s\", \" is\")\n",
    "    txt = txt.replace(\"'re\", \" are\")\n",
    "    txt = txt.replace(\"'m\", \" am\")\n",
    "    txt = txt.replace(\"'d\", \" would\")\n",
    "    txt = txt.replace(\"'ll\", \" will\")\n",
    "    \n",
    "    # More cleaning\n",
    "    txt = re.sub(r\"\\'s\", \" \", txt)\n",
    "    txt = re.sub(r\"\\'ve\", \" have \", txt)\n",
    "    txt = re.sub(r\"can't\", \"cannot \", txt)\n",
    "    txt = re.sub(r\"n't\", \" not \", txt)\n",
    "    txt = re.sub(r\"I'm\", \"I am\", txt)\n",
    "    txt = re.sub(r\" m \", \" am \", txt)\n",
    "    txt = re.sub(r\"\\'re\", \" are \", txt)\n",
    "    txt = re.sub(r\"\\'d\", \" would \", txt)\n",
    "    txt = re.sub(r\"\\'ll\", \" will \", txt)\n",
    "    txt = re.sub(r\" e g \", \" eg \", txt)\n",
    "    txt = re.sub(r\"\\0s\", \"0\", txt)\n",
    "\n",
    "    # Remove urls and emails\n",
    "    txt = re.sub(r'^https?:\\/\\/.[\\r\\n]', ' ', txt, flags=re.MULTILINE)\n",
    "    txt = re.sub(r'[\\w\\.-]+@[\\w\\.-]+', ' ', txt, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove punctuation from text\n",
    "    txt = ''.join([c for c in text if c not in punctuation])\n",
    "\n",
    "    \n",
    "    # Remove all symbols\n",
    "    txt = re.sub(r'[^A-Za-z0-9\\s]',r' ',txt)\n",
    "    txt = re.sub(r'\\n',r' ',txt)\n",
    "    \n",
    "    txt = re.sub(r'[0-9]',r' ',txt)\n",
    "    \n",
    "    # Replace words like sooooooo with so\n",
    "    txt = ''.join(''.join(s)[:2] for _, s in itertools.groupby(txt))\n",
    "    \n",
    "    # lowercase and Split (instead of tokenization, so no need to word tokenization later:-)  attached words   \n",
    "    if lowercase:\n",
    "        txt = \" \".join([w.lower() for w in txt.split()])\n",
    "        \n",
    "    if remove_stops:\n",
    "        txt = \" \".join([w for w in txt.split() if w not in stops])\n",
    "    if stemming:\n",
    "        st = PorterStemmer()\n",
    "#         print (len(txt.split()))\n",
    "#         print (txt)\n",
    "        txt = \" \".join([st.stem(w) for w in txt.split()])\n",
    "    \n",
    "    if lemmatization:\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        txt = \" \".join([wordnet_lemmatizer.lemmatize(w, pos='v') for w in txt.split()])\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bad20af-ed27-4c53-85aa-4935d4a8a9e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        i rent i be curiousyellow from my video store ...\n",
       "1        i be curiou yellow risibl pretenti steam pile ...\n",
       "2        onli avoid make type film in futur film intere...\n",
       "3        film wa probabl inspir by godard masculin f mi...\n",
       "4        oh brotheraft hear ridicul film umpteen year a...\n",
       "                               ...                        \n",
       "24995    hit at time now better categoris australian cu...\n",
       "24996    i love movi like no other anoth time i will tr...\n",
       "24997    film it sequel barri mckenzi hold hi own be tw...\n",
       "24998    adventur barri mckenzi start life satir comic ...\n",
       "24999    stori center around barri mckenzi who must go ...\n",
       "Name: text, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text = train['text'].map(lambda x: cleanData(x, lowercase=True, remove_stops=True, stemming=True, lemmatization = True))\n",
    "train.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "debdfa2d-65b8-4b9a-b3aa-c58c79213649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i rent i be curiousyellow from my video store all controversi surround it when it wa first releas in i also hear at first it wa seiz by us custom it ever tri enter countri therefor be fan film consid controversi i realli have see myselfbr br plot center around young swedish drama student name lena who want learn everyth she can life in particular she want focu her attent make some sort documentari on averag swede think certain polit issu vietnam war race issu in unit state in between ask politician ordinari denizen stockholm their opinion on polit she ha sex with her drama teacher classmat marri menbr br kill me i be curiousyellow year ago wa consid pornograph realli sex nuditi scene be few far between even it not shoot like some cheapli make porno my countrymen mind find it shock in realiti sex nuditi be major stapl in swedish cinema even ingmar bergman arguabl their answer good old boy john ford have sex scene in hi filmsbr br i do commend filmmak fact ani sex show in film show artist purpos rather shock peopl make money be show in pornograph theater in america i be curiousyellow good film anyon want studi meat potato no pun intend swedish cinema realli film doesnt have much plot'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d1a508d-c451-4de9-81f2-54c69488c6b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        i love scifi be will put up with lot scifi mov...\n",
       "1        worth entertain valu rental especi you like ac...\n",
       "2        it total averag film with few semialright acti...\n",
       "3        star rate saturday night friday night friday m...\n",
       "4        first off let me say you havent enjoy van damm...\n",
       "                               ...                        \n",
       "24995    get around see monster man yesterday it have b...\n",
       "24996    i get part competit prize i watch it not reall...\n",
       "24997    i get monster man in box set three film where ...\n",
       "24998    five minut in i start feel how naff wa look yo...\n",
       "24999    i catch movi on scifi channel recent it actual...\n",
       "Name: text, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.text = test['text'].map(lambda x: cleanData(x, lowercase=True, remove_stops=True, stemming=True, lemmatization = True))\n",
    "test.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b64b2738-6f59-4f3d-89ca-3022fd1da9de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load library\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdabaa0a-1abe-47ed-9d21-c11323c5202a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x88562 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2932741 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the bag of words feature matrix\n",
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(train.text)\n",
    "\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "708a5295-2bf4-4af7-9661-eaffffd8dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words_test = count.fit_transform(test.text)\n",
    "test_set = bag_of_words_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3ac487d-135e-4c6d-a0bc-ea9b4b09fee5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x88562 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2932741 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = bag_of_words\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4141aaa6-d132-4721-b985-b98fa7e524b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aba12946-5424-4600-ae37-6b61e1abd21a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " # Create random forest classifier object\n",
    "randomforest = RandomForestClassifier(random_state=0, n_estimators=1000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dbf6176-e6d7-4c05-96b5-7a2e55b7932e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = randomforest.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1720e6-411f-4929-b0b9-6dbe55f59413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training evaluation: Cross-validate model using accuracy\n",
    "cross_val_score(model, features, target, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc1ef08-9a8a-45b2-a3d3-84283d0f85c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model evaluation: Cross-validate model using accuracy\n",
    "cross_val_score(model, test_set, target, scoring='accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCamber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
